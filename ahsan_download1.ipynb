{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff932c3a-eedf-48fa-8cef-3bece9800d5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bs23037\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "C:\\Users\\bs23037\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "C:\\Users\\bs23037\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\layers\\rnn\\bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Deeper CNN...\n",
      "Epoch 1/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 22ms/step - accuracy: 0.8889 - loss: 0.3888 - val_accuracy: 0.9697 - val_loss: 0.1260\n",
      "Epoch 2/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 24ms/step - accuracy: 0.9681 - loss: 0.1252 - val_accuracy: 0.9811 - val_loss: 0.0723\n",
      "Epoch 3/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 26ms/step - accuracy: 0.9752 - loss: 0.0912 - val_accuracy: 0.9796 - val_loss: 0.0728\n",
      "Epoch 4/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 26ms/step - accuracy: 0.9803 - loss: 0.0748 - val_accuracy: 0.9868 - val_loss: 0.0478\n",
      "Epoch 5/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 27ms/step - accuracy: 0.9830 - loss: 0.0631 - val_accuracy: 0.9875 - val_loss: 0.0468\n",
      "Epoch 6/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 28ms/step - accuracy: 0.9854 - loss: 0.0523 - val_accuracy: 0.9885 - val_loss: 0.0456\n",
      "Epoch 7/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 26ms/step - accuracy: 0.9877 - loss: 0.0484 - val_accuracy: 0.9881 - val_loss: 0.0425\n",
      "Epoch 8/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 26ms/step - accuracy: 0.9881 - loss: 0.0411 - val_accuracy: 0.9880 - val_loss: 0.0426\n",
      "Epoch 9/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 27ms/step - accuracy: 0.9897 - loss: 0.0362 - val_accuracy: 0.9891 - val_loss: 0.0414\n",
      "Epoch 10/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 27ms/step - accuracy: 0.9898 - loss: 0.0350 - val_accuracy: 0.9895 - val_loss: 0.0368\n",
      "Epoch 11/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 27ms/step - accuracy: 0.9912 - loss: 0.0319 - val_accuracy: 0.9906 - val_loss: 0.0323\n",
      "Epoch 12/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 27ms/step - accuracy: 0.9925 - loss: 0.0282 - val_accuracy: 0.9900 - val_loss: 0.0341\n",
      "Epoch 13/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 27ms/step - accuracy: 0.9927 - loss: 0.0271 - val_accuracy: 0.9915 - val_loss: 0.0311\n",
      "Epoch 14/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 27ms/step - accuracy: 0.9927 - loss: 0.0256 - val_accuracy: 0.9915 - val_loss: 0.0305\n",
      "Epoch 15/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 27ms/step - accuracy: 0.9937 - loss: 0.0223 - val_accuracy: 0.9924 - val_loss: 0.0256\n",
      "Epoch 16/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 27ms/step - accuracy: 0.9936 - loss: 0.0206 - val_accuracy: 0.9913 - val_loss: 0.0318\n",
      "Epoch 17/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 27ms/step - accuracy: 0.9935 - loss: 0.0217 - val_accuracy: 0.9913 - val_loss: 0.0329\n",
      "Epoch 18/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 27ms/step - accuracy: 0.9939 - loss: 0.0193 - val_accuracy: 0.9916 - val_loss: 0.0302\n",
      "Epoch 19/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 27ms/step - accuracy: 0.9943 - loss: 0.0184 - val_accuracy: 0.9937 - val_loss: 0.0227\n",
      "Epoch 20/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 27ms/step - accuracy: 0.9946 - loss: 0.0169 - val_accuracy: 0.9924 - val_loss: 0.0274\n",
      "Epoch 21/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 27ms/step - accuracy: 0.9954 - loss: 0.0152 - val_accuracy: 0.9923 - val_loss: 0.0294\n",
      "Epoch 22/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 27ms/step - accuracy: 0.9950 - loss: 0.0157 - val_accuracy: 0.9905 - val_loss: 0.0340\n",
      "Epoch 23/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 27ms/step - accuracy: 0.9965 - loss: 0.0126 - val_accuracy: 0.9916 - val_loss: 0.0287\n",
      "Epoch 24/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 27ms/step - accuracy: 0.9955 - loss: 0.0140 - val_accuracy: 0.9916 - val_loss: 0.0297\n",
      "Epoch 25/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 27ms/step - accuracy: 0.9955 - loss: 0.0134 - val_accuracy: 0.9917 - val_loss: 0.0317\n",
      "Epoch 26/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 28ms/step - accuracy: 0.9962 - loss: 0.0121 - val_accuracy: 0.9925 - val_loss: 0.0309\n",
      "Epoch 27/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 28ms/step - accuracy: 0.9966 - loss: 0.0106 - val_accuracy: 0.9909 - val_loss: 0.0325\n",
      "Epoch 28/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 28ms/step - accuracy: 0.9969 - loss: 0.0104 - val_accuracy: 0.9928 - val_loss: 0.0311\n",
      "Epoch 29/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 28ms/step - accuracy: 0.9969 - loss: 0.0099 - val_accuracy: 0.9939 - val_loss: 0.0294\n",
      "Epoch 30/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 28ms/step - accuracy: 0.9972 - loss: 0.0093 - val_accuracy: 0.9920 - val_loss: 0.0339\n",
      "Epoch 31/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 28ms/step - accuracy: 0.9969 - loss: 0.0092 - val_accuracy: 0.9916 - val_loss: 0.0393\n",
      "Epoch 32/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 28ms/step - accuracy: 0.9972 - loss: 0.0086 - val_accuracy: 0.9921 - val_loss: 0.0353\n",
      "Epoch 33/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 28ms/step - accuracy: 0.9974 - loss: 0.0079 - val_accuracy: 0.9928 - val_loss: 0.0306\n",
      "Epoch 34/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 28ms/step - accuracy: 0.9979 - loss: 0.0073 - val_accuracy: 0.9936 - val_loss: 0.0313\n",
      "Epoch 35/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 28ms/step - accuracy: 0.9978 - loss: 0.0072 - val_accuracy: 0.9913 - val_loss: 0.0394\n",
      "Epoch 36/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 28ms/step - accuracy: 0.9980 - loss: 0.0062 - val_accuracy: 0.9910 - val_loss: 0.0398\n",
      "Epoch 37/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 28ms/step - accuracy: 0.9975 - loss: 0.0072 - val_accuracy: 0.9931 - val_loss: 0.0328\n",
      "Epoch 38/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 28ms/step - accuracy: 0.9978 - loss: 0.0062 - val_accuracy: 0.9923 - val_loss: 0.0416\n",
      "Epoch 39/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 28ms/step - accuracy: 0.9976 - loss: 0.0074 - val_accuracy: 0.9935 - val_loss: 0.0319\n",
      "Epoch 40/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 28ms/step - accuracy: 0.9982 - loss: 0.0054 - val_accuracy: 0.9916 - val_loss: 0.0330\n",
      "Epoch 41/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 28ms/step - accuracy: 0.9980 - loss: 0.0064 - val_accuracy: 0.9937 - val_loss: 0.0316\n",
      "Epoch 42/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 28ms/step - accuracy: 0.9982 - loss: 0.0056 - val_accuracy: 0.9937 - val_loss: 0.0277\n",
      "Epoch 43/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 28ms/step - accuracy: 0.9981 - loss: 0.0061 - val_accuracy: 0.9932 - val_loss: 0.0331\n",
      "Epoch 44/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 28ms/step - accuracy: 0.9980 - loss: 0.0056 - val_accuracy: 0.9923 - val_loss: 0.0375\n",
      "Epoch 45/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 28ms/step - accuracy: 0.9981 - loss: 0.0049 - val_accuracy: 0.9909 - val_loss: 0.0431\n",
      "Epoch 46/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 28ms/step - accuracy: 0.9982 - loss: 0.0056 - val_accuracy: 0.9938 - val_loss: 0.0309\n",
      "Epoch 47/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 28ms/step - accuracy: 0.9982 - loss: 0.0053 - val_accuracy: 0.9936 - val_loss: 0.0349\n",
      "Epoch 48/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 28ms/step - accuracy: 0.9987 - loss: 0.0039 - val_accuracy: 0.9929 - val_loss: 0.0340\n",
      "Epoch 49/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 28ms/step - accuracy: 0.9984 - loss: 0.0049 - val_accuracy: 0.9921 - val_loss: 0.0360\n",
      "Epoch 50/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 28ms/step - accuracy: 0.9984 - loss: 0.0058 - val_accuracy: 0.9929 - val_loss: 0.0395\n",
      "Total Training Time for Deeper CNN: 3407.85 seconds\n",
      "Training ResNet...\n",
      "Epoch 1/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 27ms/step - accuracy: 0.9052 - loss: 0.3194 - val_accuracy: 0.9765 - val_loss: 0.0921\n",
      "Epoch 2/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 26ms/step - accuracy: 0.9762 - loss: 0.0875 - val_accuracy: 0.9827 - val_loss: 0.0661\n",
      "Epoch 3/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 26ms/step - accuracy: 0.9828 - loss: 0.0615 - val_accuracy: 0.9869 - val_loss: 0.0475\n",
      "Epoch 4/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 26ms/step - accuracy: 0.9877 - loss: 0.0450 - val_accuracy: 0.9841 - val_loss: 0.0576\n",
      "Epoch 5/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 26ms/step - accuracy: 0.9886 - loss: 0.0390 - val_accuracy: 0.9910 - val_loss: 0.0325\n",
      "Epoch 6/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 26ms/step - accuracy: 0.9909 - loss: 0.0317 - val_accuracy: 0.9892 - val_loss: 0.0389\n",
      "Epoch 7/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 26ms/step - accuracy: 0.9921 - loss: 0.0279 - val_accuracy: 0.9858 - val_loss: 0.0503\n",
      "Epoch 8/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 26ms/step - accuracy: 0.9926 - loss: 0.0252 - val_accuracy: 0.9913 - val_loss: 0.0291\n",
      "Epoch 9/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 27ms/step - accuracy: 0.9933 - loss: 0.0228 - val_accuracy: 0.9922 - val_loss: 0.0287\n",
      "Epoch 10/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 27ms/step - accuracy: 0.9945 - loss: 0.0195 - val_accuracy: 0.9923 - val_loss: 0.0280\n",
      "Epoch 11/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 27ms/step - accuracy: 0.9949 - loss: 0.0174 - val_accuracy: 0.9909 - val_loss: 0.0298\n",
      "Epoch 12/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 27ms/step - accuracy: 0.9957 - loss: 0.0140 - val_accuracy: 0.9910 - val_loss: 0.0322\n",
      "Epoch 13/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 28ms/step - accuracy: 0.9954 - loss: 0.0141 - val_accuracy: 0.9930 - val_loss: 0.0259\n",
      "Epoch 14/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 28ms/step - accuracy: 0.9957 - loss: 0.0141 - val_accuracy: 0.9908 - val_loss: 0.0328\n",
      "Epoch 15/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 28ms/step - accuracy: 0.9959 - loss: 0.0123 - val_accuracy: 0.9928 - val_loss: 0.0297\n",
      "Epoch 16/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 28ms/step - accuracy: 0.9962 - loss: 0.0116 - val_accuracy: 0.9945 - val_loss: 0.0214\n",
      "Epoch 17/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 28ms/step - accuracy: 0.9974 - loss: 0.0082 - val_accuracy: 0.9926 - val_loss: 0.0271\n",
      "Epoch 18/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 28ms/step - accuracy: 0.9973 - loss: 0.0082 - val_accuracy: 0.9890 - val_loss: 0.0372\n",
      "Epoch 19/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 27ms/step - accuracy: 0.9970 - loss: 0.0082 - val_accuracy: 0.9939 - val_loss: 0.0272\n",
      "Epoch 20/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 27ms/step - accuracy: 0.9977 - loss: 0.0073 - val_accuracy: 0.9931 - val_loss: 0.0251\n",
      "Epoch 21/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 27ms/step - accuracy: 0.9979 - loss: 0.0069 - val_accuracy: 0.9899 - val_loss: 0.0362\n",
      "Epoch 22/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 27ms/step - accuracy: 0.9981 - loss: 0.0063 - val_accuracy: 0.9932 - val_loss: 0.0288\n",
      "Epoch 23/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 27ms/step - accuracy: 0.9981 - loss: 0.0053 - val_accuracy: 0.9937 - val_loss: 0.0281\n",
      "Epoch 24/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 27ms/step - accuracy: 0.9979 - loss: 0.0059 - val_accuracy: 0.9935 - val_loss: 0.0290\n",
      "Epoch 25/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 27ms/step - accuracy: 0.9981 - loss: 0.0062 - val_accuracy: 0.9930 - val_loss: 0.0279\n",
      "Epoch 26/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 27ms/step - accuracy: 0.9985 - loss: 0.0051 - val_accuracy: 0.9920 - val_loss: 0.0315\n",
      "Epoch 27/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 27ms/step - accuracy: 0.9983 - loss: 0.0049 - val_accuracy: 0.9935 - val_loss: 0.0266\n",
      "Epoch 28/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 27ms/step - accuracy: 0.9985 - loss: 0.0052 - val_accuracy: 0.9938 - val_loss: 0.0255\n",
      "Epoch 29/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 28ms/step - accuracy: 0.9987 - loss: 0.0047 - val_accuracy: 0.9935 - val_loss: 0.0341\n",
      "Epoch 30/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 29ms/step - accuracy: 0.9988 - loss: 0.0041 - val_accuracy: 0.9946 - val_loss: 0.0260\n",
      "Epoch 31/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 28ms/step - accuracy: 0.9987 - loss: 0.0035 - val_accuracy: 0.9926 - val_loss: 0.0354\n",
      "Epoch 32/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 27ms/step - accuracy: 0.9985 - loss: 0.0045 - val_accuracy: 0.9940 - val_loss: 0.0282\n",
      "Epoch 33/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 27ms/step - accuracy: 0.9989 - loss: 0.0035 - val_accuracy: 0.9942 - val_loss: 0.0259\n",
      "Epoch 34/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 28ms/step - accuracy: 0.9988 - loss: 0.0033 - val_accuracy: 0.9924 - val_loss: 0.0374\n",
      "Epoch 35/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 28ms/step - accuracy: 0.9983 - loss: 0.0046 - val_accuracy: 0.9931 - val_loss: 0.0334\n",
      "Epoch 36/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 28ms/step - accuracy: 0.9991 - loss: 0.0031 - val_accuracy: 0.9824 - val_loss: 0.0770\n",
      "Epoch 37/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 26ms/step - accuracy: 0.9988 - loss: 0.0036 - val_accuracy: 0.9929 - val_loss: 0.0313\n",
      "Epoch 38/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 26ms/step - accuracy: 0.9990 - loss: 0.0032 - val_accuracy: 0.9867 - val_loss: 0.0475\n",
      "Epoch 39/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 26ms/step - accuracy: 0.9994 - loss: 0.0023 - val_accuracy: 0.9944 - val_loss: 0.0276\n",
      "Epoch 40/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 26ms/step - accuracy: 0.9994 - loss: 0.0024 - val_accuracy: 0.9934 - val_loss: 0.0269\n",
      "Epoch 41/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 26ms/step - accuracy: 0.9988 - loss: 0.0036 - val_accuracy: 0.9920 - val_loss: 0.0344\n",
      "Epoch 42/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 26ms/step - accuracy: 0.9991 - loss: 0.0027 - val_accuracy: 0.9923 - val_loss: 0.0355\n",
      "Epoch 43/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 26ms/step - accuracy: 0.9991 - loss: 0.0031 - val_accuracy: 0.9939 - val_loss: 0.0306\n",
      "Epoch 44/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 26ms/step - accuracy: 0.9992 - loss: 0.0027 - val_accuracy: 0.9926 - val_loss: 0.0352\n",
      "Epoch 45/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 26ms/step - accuracy: 0.9992 - loss: 0.0033 - val_accuracy: 0.9939 - val_loss: 0.0338\n",
      "Epoch 46/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 27ms/step - accuracy: 0.9991 - loss: 0.0028 - val_accuracy: 0.9635 - val_loss: 0.1724\n",
      "Epoch 47/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 27ms/step - accuracy: 0.9995 - loss: 0.0016 - val_accuracy: 0.9914 - val_loss: 0.0465\n",
      "Epoch 48/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 27ms/step - accuracy: 0.9984 - loss: 0.0046 - val_accuracy: 0.9952 - val_loss: 0.0296\n",
      "Epoch 49/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 27ms/step - accuracy: 0.9988 - loss: 0.0039 - val_accuracy: 0.9955 - val_loss: 0.0241\n",
      "Epoch 50/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 27ms/step - accuracy: 0.9993 - loss: 0.0022 - val_accuracy: 0.9942 - val_loss: 0.0306\n",
      "Total Training Time for ResNet: 3375.52 seconds\n",
      "Training Stacked GRU...\n",
      "Epoch 1/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 67ms/step - accuracy: 0.7186 - loss: 1.0699 - val_accuracy: 0.7533 - val_loss: 0.8572\n",
      "Epoch 2/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 66ms/step - accuracy: 0.7516 - loss: 0.8854 - val_accuracy: 0.7533 - val_loss: 0.8320\n",
      "Epoch 3/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 66ms/step - accuracy: 0.7516 - loss: 0.8594 - val_accuracy: 0.7533 - val_loss: 0.8194\n",
      "Epoch 4/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 66ms/step - accuracy: 0.7480 - loss: 0.8494 - val_accuracy: 0.7533 - val_loss: 0.7962\n",
      "Epoch 5/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 66ms/step - accuracy: 0.7511 - loss: 0.8063 - val_accuracy: 0.7533 - val_loss: 0.7247\n",
      "Epoch 6/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 66ms/step - accuracy: 0.7502 - loss: 0.7310 - val_accuracy: 0.7568 - val_loss: 0.6647\n",
      "Epoch 7/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 66ms/step - accuracy: 0.7633 - loss: 0.6751 - val_accuracy: 0.8002 - val_loss: 0.5796\n",
      "Epoch 8/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 66ms/step - accuracy: 0.7960 - loss: 0.5889 - val_accuracy: 0.8304 - val_loss: 0.4978\n",
      "Epoch 9/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 67ms/step - accuracy: 0.8204 - loss: 0.5172 - val_accuracy: 0.8468 - val_loss: 0.4381\n",
      "Epoch 10/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 66ms/step - accuracy: 0.8402 - loss: 0.4669 - val_accuracy: 0.8633 - val_loss: 0.3973\n",
      "Epoch 11/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 66ms/step - accuracy: 0.8562 - loss: 0.4290 - val_accuracy: 0.8715 - val_loss: 0.3859\n",
      "Epoch 12/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 66ms/step - accuracy: 0.8674 - loss: 0.4031 - val_accuracy: 0.8881 - val_loss: 0.3391\n",
      "Epoch 13/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 66ms/step - accuracy: 0.8825 - loss: 0.3708 - val_accuracy: 0.9045 - val_loss: 0.3132\n",
      "Epoch 14/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 66ms/step - accuracy: 0.8941 - loss: 0.3440 - val_accuracy: 0.9041 - val_loss: 0.3074\n",
      "Epoch 15/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 66ms/step - accuracy: 0.8994 - loss: 0.3320 - val_accuracy: 0.9191 - val_loss: 0.2750\n",
      "Epoch 16/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 66ms/step - accuracy: 0.9072 - loss: 0.3139 - val_accuracy: 0.9261 - val_loss: 0.2599\n",
      "Epoch 17/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 66ms/step - accuracy: 0.9107 - loss: 0.3071 - val_accuracy: 0.9279 - val_loss: 0.2476\n",
      "Epoch 18/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 66ms/step - accuracy: 0.9177 - loss: 0.2890 - val_accuracy: 0.9288 - val_loss: 0.2506\n",
      "Epoch 19/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 66ms/step - accuracy: 0.9215 - loss: 0.2777 - val_accuracy: 0.9391 - val_loss: 0.2189\n",
      "Epoch 20/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 66ms/step - accuracy: 0.9276 - loss: 0.2670 - val_accuracy: 0.9423 - val_loss: 0.2150\n",
      "Epoch 21/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 67ms/step - accuracy: 0.9310 - loss: 0.2527 - val_accuracy: 0.9448 - val_loss: 0.2005\n",
      "Epoch 22/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 66ms/step - accuracy: 0.9348 - loss: 0.2421 - val_accuracy: 0.9459 - val_loss: 0.1948\n",
      "Epoch 23/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 63ms/step - accuracy: 0.9379 - loss: 0.2332 - val_accuracy: 0.9461 - val_loss: 0.1936\n",
      "Epoch 24/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 66ms/step - accuracy: 0.9426 - loss: 0.2177 - val_accuracy: 0.9523 - val_loss: 0.1782\n",
      "Epoch 25/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 67ms/step - accuracy: 0.9432 - loss: 0.2134 - val_accuracy: 0.9544 - val_loss: 0.1714\n",
      "Epoch 26/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 66ms/step - accuracy: 0.9466 - loss: 0.2054 - val_accuracy: 0.9571 - val_loss: 0.1662\n",
      "Epoch 27/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 67ms/step - accuracy: 0.9483 - loss: 0.2013 - val_accuracy: 0.9539 - val_loss: 0.1728\n",
      "Epoch 28/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 66ms/step - accuracy: 0.9496 - loss: 0.1962 - val_accuracy: 0.9580 - val_loss: 0.1575\n",
      "Epoch 29/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 67ms/step - accuracy: 0.9505 - loss: 0.1902 - val_accuracy: 0.9571 - val_loss: 0.1542\n",
      "Epoch 30/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 66ms/step - accuracy: 0.9531 - loss: 0.1850 - val_accuracy: 0.9605 - val_loss: 0.1493\n",
      "Epoch 31/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 64ms/step - accuracy: 0.9521 - loss: 0.1846 - val_accuracy: 0.9604 - val_loss: 0.1511\n",
      "Epoch 32/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 66ms/step - accuracy: 0.9546 - loss: 0.1779 - val_accuracy: 0.9570 - val_loss: 0.1551\n",
      "Epoch 33/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 66ms/step - accuracy: 0.9547 - loss: 0.1773 - val_accuracy: 0.9614 - val_loss: 0.1459\n",
      "Epoch 34/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 66ms/step - accuracy: 0.9580 - loss: 0.1689 - val_accuracy: 0.9625 - val_loss: 0.1445\n",
      "Epoch 35/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 66ms/step - accuracy: 0.9570 - loss: 0.1696 - val_accuracy: 0.9653 - val_loss: 0.1329\n",
      "Epoch 36/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 67ms/step - accuracy: 0.9591 - loss: 0.1640 - val_accuracy: 0.9642 - val_loss: 0.1367\n",
      "Epoch 37/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 67ms/step - accuracy: 0.9611 - loss: 0.1520 - val_accuracy: 0.9638 - val_loss: 0.1333\n",
      "Epoch 38/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 67ms/step - accuracy: 0.9605 - loss: 0.1552 - val_accuracy: 0.9637 - val_loss: 0.1352\n",
      "Epoch 39/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 67ms/step - accuracy: 0.9612 - loss: 0.1512 - val_accuracy: 0.9646 - val_loss: 0.1349\n",
      "Epoch 40/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 66ms/step - accuracy: 0.9632 - loss: 0.1492 - val_accuracy: 0.9684 - val_loss: 0.1225\n",
      "Epoch 41/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 67ms/step - accuracy: 0.9632 - loss: 0.1499 - val_accuracy: 0.9678 - val_loss: 0.1227\n",
      "Epoch 42/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 67ms/step - accuracy: 0.9630 - loss: 0.1468 - val_accuracy: 0.9672 - val_loss: 0.1220\n",
      "Epoch 43/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 67ms/step - accuracy: 0.9647 - loss: 0.1429 - val_accuracy: 0.9692 - val_loss: 0.1141\n",
      "Epoch 44/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 64ms/step - accuracy: 0.9638 - loss: 0.1436 - val_accuracy: 0.9667 - val_loss: 0.1232\n",
      "Epoch 45/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 65ms/step - accuracy: 0.9661 - loss: 0.1347 - val_accuracy: 0.9704 - val_loss: 0.1164\n",
      "Epoch 46/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 67ms/step - accuracy: 0.9661 - loss: 0.1368 - val_accuracy: 0.9717 - val_loss: 0.1099\n",
      "Epoch 47/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m168s\u001b[0m 67ms/step - accuracy: 0.9664 - loss: 0.1353 - val_accuracy: 0.9718 - val_loss: 0.1094\n",
      "Epoch 48/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 65ms/step - accuracy: 0.9671 - loss: 0.1284 - val_accuracy: 0.9706 - val_loss: 0.1116\n",
      "Epoch 49/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 65ms/step - accuracy: 0.9681 - loss: 0.1278 - val_accuracy: 0.9707 - val_loss: 0.1118\n",
      "Epoch 50/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 67ms/step - accuracy: 0.9686 - loss: 0.1274 - val_accuracy: 0.9715 - val_loss: 0.1082\n",
      "Total Training Time for Stacked GRU: 8281.73 seconds\n",
      "Training Vanilla LSTM...\n",
      "Epoch 1/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 23ms/step - accuracy: 0.7083 - loss: 1.1350 - val_accuracy: 0.7533 - val_loss: 0.8576\n",
      "Epoch 2/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 23ms/step - accuracy: 0.7477 - loss: 0.8950 - val_accuracy: 0.7533 - val_loss: 0.7537\n",
      "Epoch 3/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 23ms/step - accuracy: 0.7516 - loss: 0.7829 - val_accuracy: 0.7797 - val_loss: 0.6530\n",
      "Epoch 4/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 23ms/step - accuracy: 0.7790 - loss: 0.6846 - val_accuracy: 0.7953 - val_loss: 0.5913\n",
      "Epoch 5/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 24ms/step - accuracy: 0.7975 - loss: 0.6283 - val_accuracy: 0.8237 - val_loss: 0.5219\n",
      "Epoch 6/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 25ms/step - accuracy: 0.8112 - loss: 0.5866 - val_accuracy: 0.8446 - val_loss: 0.4874\n",
      "Epoch 7/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 25ms/step - accuracy: 0.8268 - loss: 0.5304 - val_accuracy: 0.7922 - val_loss: 0.5904\n",
      "Epoch 8/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 25ms/step - accuracy: 0.8272 - loss: 0.5169 - val_accuracy: 0.8449 - val_loss: 0.4536\n",
      "Epoch 9/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 24ms/step - accuracy: 0.8328 - loss: 0.4901 - val_accuracy: 0.8463 - val_loss: 0.4407\n",
      "Epoch 10/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 25ms/step - accuracy: 0.8355 - loss: 0.4710 - val_accuracy: 0.8492 - val_loss: 0.4211\n",
      "Epoch 11/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 25ms/step - accuracy: 0.8387 - loss: 0.4600 - val_accuracy: 0.8565 - val_loss: 0.4062\n",
      "Epoch 12/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 25ms/step - accuracy: 0.8450 - loss: 0.4377 - val_accuracy: 0.8643 - val_loss: 0.3896\n",
      "Epoch 13/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 26ms/step - accuracy: 0.8441 - loss: 0.4413 - val_accuracy: 0.8676 - val_loss: 0.3869\n",
      "Epoch 14/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 25ms/step - accuracy: 0.8496 - loss: 0.4342 - val_accuracy: 0.8717 - val_loss: 0.3723\n",
      "Epoch 15/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 25ms/step - accuracy: 0.8567 - loss: 0.4086 - val_accuracy: 0.8777 - val_loss: 0.3594\n",
      "Epoch 16/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 26ms/step - accuracy: 0.8606 - loss: 0.3995 - val_accuracy: 0.8741 - val_loss: 0.3683\n",
      "Epoch 17/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 25ms/step - accuracy: 0.8612 - loss: 0.3967 - val_accuracy: 0.8806 - val_loss: 0.3440\n",
      "Epoch 18/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 26ms/step - accuracy: 0.8653 - loss: 0.3885 - val_accuracy: 0.8826 - val_loss: 0.3405\n",
      "Epoch 19/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 26ms/step - accuracy: 0.8692 - loss: 0.3769 - val_accuracy: 0.8888 - val_loss: 0.3312\n",
      "Epoch 20/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 26ms/step - accuracy: 0.8786 - loss: 0.3624 - val_accuracy: 0.8930 - val_loss: 0.3286\n",
      "Epoch 21/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 26ms/step - accuracy: 0.8800 - loss: 0.3650 - val_accuracy: 0.8929 - val_loss: 0.3347\n",
      "Epoch 22/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 26ms/step - accuracy: 0.8831 - loss: 0.3550 - val_accuracy: 0.8995 - val_loss: 0.3102\n",
      "Epoch 23/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 26ms/step - accuracy: 0.8887 - loss: 0.3450 - val_accuracy: 0.9023 - val_loss: 0.3082\n",
      "Epoch 24/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 26ms/step - accuracy: 0.8911 - loss: 0.3397 - val_accuracy: 0.8974 - val_loss: 0.3064\n",
      "Epoch 25/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 25ms/step - accuracy: 0.8933 - loss: 0.3351 - val_accuracy: 0.9011 - val_loss: 0.3099\n",
      "Epoch 26/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 25ms/step - accuracy: 0.8939 - loss: 0.3335 - val_accuracy: 0.9135 - val_loss: 0.2837\n",
      "Epoch 27/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 25ms/step - accuracy: 0.8995 - loss: 0.3189 - val_accuracy: 0.9204 - val_loss: 0.2719\n",
      "Epoch 28/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 25ms/step - accuracy: 0.9001 - loss: 0.3186 - val_accuracy: 0.9208 - val_loss: 0.2781\n",
      "Epoch 29/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 25ms/step - accuracy: 0.9039 - loss: 0.3166 - val_accuracy: 0.9291 - val_loss: 0.2578\n",
      "Epoch 30/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 25ms/step - accuracy: 0.9030 - loss: 0.3176 - val_accuracy: 0.9264 - val_loss: 0.2607\n",
      "Epoch 31/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 25ms/step - accuracy: 0.9121 - loss: 0.2954 - val_accuracy: 0.9328 - val_loss: 0.2537\n",
      "Epoch 32/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 25ms/step - accuracy: 0.9111 - loss: 0.3033 - val_accuracy: 0.9126 - val_loss: 0.2767\n",
      "Epoch 33/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 25ms/step - accuracy: 0.9117 - loss: 0.2980 - val_accuracy: 0.9315 - val_loss: 0.2547\n",
      "Epoch 34/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 25ms/step - accuracy: 0.9128 - loss: 0.3028 - val_accuracy: 0.9246 - val_loss: 0.2689\n",
      "Epoch 35/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 25ms/step - accuracy: 0.9161 - loss: 0.2889 - val_accuracy: 0.9371 - val_loss: 0.2364\n",
      "Epoch 36/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 26ms/step - accuracy: 0.9172 - loss: 0.2883 - val_accuracy: 0.9411 - val_loss: 0.2294\n",
      "Epoch 37/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 25ms/step - accuracy: 0.9201 - loss: 0.2811 - val_accuracy: 0.9383 - val_loss: 0.2346\n",
      "Epoch 38/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 25ms/step - accuracy: 0.9225 - loss: 0.2746 - val_accuracy: 0.9395 - val_loss: 0.2309\n",
      "Epoch 39/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 25ms/step - accuracy: 0.9212 - loss: 0.2871 - val_accuracy: 0.9444 - val_loss: 0.2238\n",
      "Epoch 40/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 26ms/step - accuracy: 0.9232 - loss: 0.2751 - val_accuracy: 0.9442 - val_loss: 0.2173\n",
      "Epoch 41/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 26ms/step - accuracy: 0.9191 - loss: 0.2822 - val_accuracy: 0.9410 - val_loss: 0.2273\n",
      "Epoch 42/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 26ms/step - accuracy: 0.9286 - loss: 0.2577 - val_accuracy: 0.9451 - val_loss: 0.2163\n",
      "Epoch 43/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 25ms/step - accuracy: 0.9292 - loss: 0.2562 - val_accuracy: 0.9488 - val_loss: 0.2082\n",
      "Epoch 44/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 26ms/step - accuracy: 0.9326 - loss: 0.2462 - val_accuracy: 0.9495 - val_loss: 0.2026\n",
      "Epoch 45/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 26ms/step - accuracy: 0.9282 - loss: 0.2618 - val_accuracy: 0.9486 - val_loss: 0.2063\n",
      "Epoch 46/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 26ms/step - accuracy: 0.9306 - loss: 0.2536 - val_accuracy: 0.9392 - val_loss: 0.2337\n",
      "Epoch 47/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 26ms/step - accuracy: 0.9303 - loss: 0.2583 - val_accuracy: 0.9503 - val_loss: 0.2057\n",
      "Epoch 48/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 26ms/step - accuracy: 0.9332 - loss: 0.2451 - val_accuracy: 0.9484 - val_loss: 0.2049\n",
      "Epoch 49/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 26ms/step - accuracy: 0.9322 - loss: 0.2492 - val_accuracy: 0.9511 - val_loss: 0.1980\n",
      "Epoch 50/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 25ms/step - accuracy: 0.9337 - loss: 0.2456 - val_accuracy: 0.9442 - val_loss: 0.2300\n",
      "Total Training Time for Vanilla LSTM: 3152.99 seconds\n",
      "Training Stacked LSTM...\n",
      "Epoch 1/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 50ms/step - accuracy: 0.7198 - loss: 1.0646 - val_accuracy: 0.7533 - val_loss: 0.7924\n",
      "Epoch 2/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 50ms/step - accuracy: 0.7502 - loss: 0.8561 - val_accuracy: 0.7533 - val_loss: 0.7621\n",
      "Epoch 3/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 50ms/step - accuracy: 0.7480 - loss: 0.8292 - val_accuracy: 0.7533 - val_loss: 0.7389\n",
      "Epoch 4/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 50ms/step - accuracy: 0.7502 - loss: 0.7695 - val_accuracy: 0.7533 - val_loss: 0.7305\n",
      "Epoch 5/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 51ms/step - accuracy: 0.7534 - loss: 0.7631 - val_accuracy: 0.7533 - val_loss: 0.7887\n",
      "Epoch 6/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 50ms/step - accuracy: 0.7506 - loss: 0.7891 - val_accuracy: 0.7533 - val_loss: 0.8012\n",
      "Epoch 7/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 50ms/step - accuracy: 0.7576 - loss: 0.7762 - val_accuracy: 0.7555 - val_loss: 0.7322\n",
      "Epoch 8/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 50ms/step - accuracy: 0.7621 - loss: 0.7323 - val_accuracy: 0.7806 - val_loss: 0.6703\n",
      "Epoch 9/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 50ms/step - accuracy: 0.7640 - loss: 0.7119 - val_accuracy: 0.7528 - val_loss: 0.7756\n",
      "Epoch 10/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 50ms/step - accuracy: 0.7594 - loss: 0.7259 - val_accuracy: 0.7694 - val_loss: 0.6612\n",
      "Epoch 11/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 50ms/step - accuracy: 0.7455 - loss: 0.7519 - val_accuracy: 0.7917 - val_loss: 0.5819\n",
      "Epoch 12/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 50ms/step - accuracy: 0.7687 - loss: 0.6436 - val_accuracy: 0.7948 - val_loss: 0.5765\n",
      "Epoch 13/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 50ms/step - accuracy: 0.7705 - loss: 0.6379 - val_accuracy: 0.7707 - val_loss: 0.7045\n",
      "Epoch 14/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 50ms/step - accuracy: 0.7786 - loss: 0.6441 - val_accuracy: 0.8188 - val_loss: 0.5206\n",
      "Epoch 15/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 51ms/step - accuracy: 0.7981 - loss: 0.5753 - val_accuracy: 0.7934 - val_loss: 0.6094\n",
      "Epoch 16/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 50ms/step - accuracy: 0.7683 - loss: 0.7335 - val_accuracy: 0.8081 - val_loss: 0.5531\n",
      "Epoch 17/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 51ms/step - accuracy: 0.8031 - loss: 0.5731 - val_accuracy: 0.8375 - val_loss: 0.4834\n",
      "Epoch 18/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 51ms/step - accuracy: 0.8135 - loss: 0.5533 - val_accuracy: 0.8592 - val_loss: 0.4242\n",
      "Epoch 19/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 50ms/step - accuracy: 0.8354 - loss: 0.5175 - val_accuracy: 0.7952 - val_loss: 0.6482\n",
      "Epoch 20/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 51ms/step - accuracy: 0.7933 - loss: 0.6666 - val_accuracy: 0.7604 - val_loss: 0.7671\n",
      "Epoch 21/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 51ms/step - accuracy: 0.7764 - loss: 0.7286 - val_accuracy: 0.7758 - val_loss: 0.7744\n",
      "Epoch 22/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 51ms/step - accuracy: 0.7812 - loss: 0.6704 - val_accuracy: 0.8321 - val_loss: 0.4684\n",
      "Epoch 23/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 49ms/step - accuracy: 0.8515 - loss: 0.4576 - val_accuracy: 0.8723 - val_loss: 0.4175\n",
      "Epoch 29/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 49ms/step - accuracy: 0.8663 - loss: 0.4254 - val_accuracy: 0.8863 - val_loss: 0.3575\n",
      "Epoch 30/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 49ms/step - accuracy: 0.8724 - loss: 0.4198 - val_accuracy: 0.8263 - val_loss: 0.4504\n",
      "Epoch 31/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 49ms/step - accuracy: 0.8423 - loss: 0.4626 - val_accuracy: 0.8772 - val_loss: 0.3739\n",
      "Epoch 32/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 49ms/step - accuracy: 0.8650 - loss: 0.4113 - val_accuracy: 0.8734 - val_loss: 0.3712\n",
      "Epoch 33/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 49ms/step - accuracy: 0.8741 - loss: 0.4002 - val_accuracy: 0.8835 - val_loss: 0.3640\n",
      "Epoch 34/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 50ms/step - accuracy: 0.8703 - loss: 0.4107 - val_accuracy: 0.7085 - val_loss: 0.8484\n",
      "Epoch 35/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 51ms/step - accuracy: 0.8028 - loss: 0.6075 - val_accuracy: 0.8788 - val_loss: 0.3783\n",
      "Epoch 36/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 51ms/step - accuracy: 0.8738 - loss: 0.4220 - val_accuracy: 0.9100 - val_loss: 0.3064\n",
      "Epoch 37/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 50ms/step - accuracy: 0.8971 - loss: 0.3487 - val_accuracy: 0.8944 - val_loss: 0.3153\n",
      "Epoch 38/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 49ms/step - accuracy: 0.8325 - loss: 0.5216 - val_accuracy: 0.8695 - val_loss: 0.4010\n",
      "Epoch 39/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 49ms/step - accuracy: 0.8664 - loss: 0.4072 - val_accuracy: 0.7919 - val_loss: 0.6574\n",
      "Epoch 40/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 49ms/step - accuracy: 0.8831 - loss: 0.3771 - val_accuracy: 0.8830 - val_loss: 0.3780\n",
      "Epoch 41/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 49ms/step - accuracy: 0.8951 - loss: 0.3601 - val_accuracy: 0.9248 - val_loss: 0.2509\n",
      "Epoch 42/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 50ms/step - accuracy: 0.9085 - loss: 0.3163 - val_accuracy: 0.9135 - val_loss: 0.2938\n",
      "Epoch 43/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 51ms/step - accuracy: 0.8801 - loss: 0.3991 - val_accuracy: 0.9086 - val_loss: 0.2800\n",
      "Epoch 44/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 49ms/step - accuracy: 0.9034 - loss: 0.3251 - val_accuracy: 0.9187 - val_loss: 0.2570\n",
      "Epoch 45/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 49ms/step - accuracy: 0.9043 - loss: 0.3293 - val_accuracy: 0.9269 - val_loss: 0.2516\n",
      "Epoch 46/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 49ms/step - accuracy: 0.8899 - loss: 0.3765 - val_accuracy: 0.8447 - val_loss: 0.4881\n",
      "Epoch 47/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 49ms/step - accuracy: 0.8369 - loss: 0.5006 - val_accuracy: 0.8862 - val_loss: 0.3613\n",
      "Epoch 48/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 49ms/step - accuracy: 0.8739 - loss: 0.3913 - val_accuracy: 0.9067 - val_loss: 0.2915\n",
      "Epoch 49/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 49ms/step - accuracy: 0.8909 - loss: 0.3388 - val_accuracy: 0.9170 - val_loss: 0.2620\n",
      "Epoch 50/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 49ms/step - accuracy: 0.9118 - loss: 0.3012 - val_accuracy: 0.9384 - val_loss: 0.2172\n",
      "Total Training Time for Stacked LSTM: 6257.02 seconds\n",
      "Training Bidirectional LSTM...\n",
      "Epoch 1/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 64ms/step - accuracy: 0.7286 - loss: 1.0159 - val_accuracy: 0.8268 - val_loss: 0.5293\n",
      "Epoch 2/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 63ms/step - accuracy: 0.8259 - loss: 0.5511 - val_accuracy: 0.8878 - val_loss: 0.3575\n",
      "Epoch 3/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 63ms/step - accuracy: 0.8818 - loss: 0.4077 - val_accuracy: 0.9227 - val_loss: 0.2921\n",
      "Epoch 4/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 63ms/step - accuracy: 0.9008 - loss: 0.3555 - val_accuracy: 0.9368 - val_loss: 0.2497\n",
      "Epoch 5/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 63ms/step - accuracy: 0.9130 - loss: 0.3155 - val_accuracy: 0.9394 - val_loss: 0.2306\n",
      "Epoch 6/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 63ms/step - accuracy: 0.9201 - loss: 0.2933 - val_accuracy: 0.9433 - val_loss: 0.2174\n",
      "Epoch 7/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 63ms/step - accuracy: 0.9259 - loss: 0.2786 - val_accuracy: 0.9436 - val_loss: 0.2038\n",
      "Epoch 8/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 63ms/step - accuracy: 0.9276 - loss: 0.2689 - val_accuracy: 0.9511 - val_loss: 0.1881\n",
      "Epoch 9/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 63ms/step - accuracy: 0.9328 - loss: 0.2497 - val_accuracy: 0.9527 - val_loss: 0.1800\n",
      "Epoch 10/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 63ms/step - accuracy: 0.9378 - loss: 0.2391 - val_accuracy: 0.9542 - val_loss: 0.1731\n",
      "Epoch 11/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 63ms/step - accuracy: 0.9374 - loss: 0.2339 - val_accuracy: 0.9559 - val_loss: 0.1658\n",
      "Epoch 12/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 63ms/step - accuracy: 0.9435 - loss: 0.2149 - val_accuracy: 0.9602 - val_loss: 0.1539\n",
      "Epoch 13/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 63ms/step - accuracy: 0.9430 - loss: 0.2188 - val_accuracy: 0.9572 - val_loss: 0.1577\n",
      "Epoch 14/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 63ms/step - accuracy: 0.9464 - loss: 0.2022 - val_accuracy: 0.9457 - val_loss: 0.1871\n",
      "Epoch 15/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 63ms/step - accuracy: 0.9448 - loss: 0.2088 - val_accuracy: 0.9624 - val_loss: 0.1385\n",
      "Epoch 16/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 63ms/step - accuracy: 0.9467 - loss: 0.2022 - val_accuracy: 0.9590 - val_loss: 0.1468\n",
      "Epoch 17/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 63ms/step - accuracy: 0.9508 - loss: 0.1942 - val_accuracy: 0.9654 - val_loss: 0.1349\n",
      "Epoch 18/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 63ms/step - accuracy: 0.9531 - loss: 0.1860 - val_accuracy: 0.9676 - val_loss: 0.1264\n",
      "Epoch 19/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 63ms/step - accuracy: 0.9529 - loss: 0.1796 - val_accuracy: 0.9664 - val_loss: 0.1275\n",
      "Epoch 20/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 63ms/step - accuracy: 0.9531 - loss: 0.1774 - val_accuracy: 0.9701 - val_loss: 0.1174\n",
      "Epoch 21/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 63ms/step - accuracy: 0.9550 - loss: 0.1725 - val_accuracy: 0.9660 - val_loss: 0.1229\n",
      "Epoch 22/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 63ms/step - accuracy: 0.9554 - loss: 0.1665 - val_accuracy: 0.9706 - val_loss: 0.1114\n",
      "Epoch 23/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 63ms/step - accuracy: 0.9576 - loss: 0.1612 - val_accuracy: 0.9646 - val_loss: 0.1270\n",
      "Epoch 24/50\n",
      "\u001b[1m2027/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m29s\u001b[0m 61ms/step - accuracy: 0.9595 - loss: 0.1582"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import wfdb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, LSTM, GRU, Reshape, Add, Input, Flatten, Bidirectional, GlobalAveragePooling2D, Dropout, BatchNormalization\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "# Define the path to the extracted dataset\n",
    "data_path = 'M:\\Dissertation\\mit-bih-arrhythmia-database-1.0.0-20240722T094228Z-001\\mit-bih-arrhythmia-database-1.0.0'\n",
    "\n",
    "# Function to load a record and preprocess\n",
    "def load_and_preprocess(record):\n",
    "    signal, fields = wfdb.rdsamp(os.path.join(data_path, record))\n",
    "    annotation = wfdb.rdann(os.path.join(data_path, record), 'atr')\n",
    "    \n",
    "    # Use only one channel (e.g., channel 0)\n",
    "    signal = signal[:, 0].reshape(-1, 1)\n",
    "    \n",
    "    # Segment the signal\n",
    "    segments = []\n",
    "    labels = []\n",
    "    for i in range(len(annotation.sample)):\n",
    "        if annotation.sample[i] - 99 > 0 and annotation.sample[i] + 160 < len(signal):\n",
    "            segments.append(signal[annotation.sample[i] - 99 : annotation.sample[i] + 161])\n",
    "            labels.append(annotation.symbol[i])\n",
    "    \n",
    "    return np.array(segments), np.array(labels)\n",
    "\n",
    "# Function to load and preprocess all records in the dataset\n",
    "def load_and_preprocess_all_records(data_path):\n",
    "    all_segments = []\n",
    "    all_labels = []\n",
    "    \n",
    "    for record in os.listdir(data_path):\n",
    "        if record.endswith('.dat'):\n",
    "            record_name = record[:-4]  # Remove the file extension\n",
    "            segments, labels = load_and_preprocess(record_name)\n",
    "            all_segments.append(segments)\n",
    "            all_labels.append(labels)\n",
    "    \n",
    "    # Concatenate all segments and labels\n",
    "    all_segments = np.vstack(all_segments)\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "    \n",
    "    return all_segments, all_labels\n",
    "\n",
    "# Load and preprocess the entire dataset\n",
    "segments, labels = load_and_preprocess_all_records(data_path)\n",
    "\n",
    "# Filter out unwanted labels (keeping only certain labels, e.g., 'N', 'L', 'R', 'A', 'V')\n",
    "valid_labels = ['N', 'L', 'R', 'A', 'V']\n",
    "mask = np.isin(labels, valid_labels)\n",
    "segments = segments[mask]\n",
    "labels = labels[mask]\n",
    "\n",
    "# Reshape segments to fit the model's expected input shape\n",
    "segments = segments.reshape(segments.shape[0], segments.shape[1], 1, 1)\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "labels_encoded = label_encoder.fit_transform(labels)\n",
    "\n",
    "# Convert labels to categorical format\n",
    "labels_categorical = tf.keras.utils.to_categorical(labels_encoded)\n",
    "\n",
    "# Split the data into training, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(segments, labels_categorical, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# 1. Deeper CNN Model with Regularization and Batch Normalization\n",
    "def create_deeper_cnn(input_shape, num_classes):\n",
    "    model = Sequential([\n",
    "        Conv2D(64, (5, 1), activation='relu', input_shape=input_shape),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2, 1)),\n",
    "        Conv2D(128, (3, 1), activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2, 1)),\n",
    "        Conv2D(256, (3, 1), activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2, 1)),\n",
    "        Conv2D(512, (3, 1), activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        GlobalAveragePooling2D(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# 2. ResNet-like Model with Regularization\n",
    "def create_resnet(input_shape, num_classes):\n",
    "    def residual_block(x, filters):\n",
    "        shortcut = x\n",
    "        x = Conv2D(filters, (3, 1), activation='relu', padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Conv2D(filters, (3, 1), activation='relu', padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        \n",
    "        # Adjust the shortcut to have the same number of filters as x\n",
    "        shortcut = Conv2D(filters, (1, 1), activation='linear', padding='same')(shortcut)\n",
    "        x = Add()([x, shortcut])\n",
    "        return x\n",
    "\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = Conv2D(64, (3, 1), activation='relu', padding='same')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D((2, 1))(x)\n",
    "    x = residual_block(x, 64)\n",
    "    x = MaxPooling2D((2, 1))(x)\n",
    "    x = residual_block(x, 128)\n",
    "    x = MaxPooling2D((2, 1))(x)\n",
    "    x = residual_block(x, 256)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    Dropout(0.5)(x)\n",
    "    outputs = Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs, outputs)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# 3. Stacked GRU Model with Regularization\n",
    "def create_stacked_gru(input_shape, num_classes):\n",
    "    model = Sequential([\n",
    "        GRU(32, return_sequences=True, input_shape=input_shape),\n",
    "        GRU(32),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# 4. Vanilla LSTM Model with Regularization\n",
    "def create_vanilla_lstm(input_shape, num_classes):\n",
    "    model = Sequential([\n",
    "        LSTM(32, input_shape=input_shape),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# 5. Stacked LSTM Model with Regularization\n",
    "def create_stacked_lstm(input_shape, num_classes):\n",
    "    model = Sequential([\n",
    "        LSTM(32, return_sequences=True, input_shape=input_shape),\n",
    "        LSTM(32),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# 6. Bidirectional LSTM Model with Regularization\n",
    "def create_bidirectional_lstm(input_shape, num_classes):\n",
    "    model = Sequential([\n",
    "        Bidirectional(LSTM(32, return_sequences=True), input_shape=input_shape),\n",
    "        Bidirectional(LSTM(32)),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# 7. CNN-LSTM Model with Regularization\n",
    "def create_cnn_lstm(input_shape_cnn, input_shape_lstm, num_classes):\n",
    "    cnn_model = Sequential([\n",
    "        Conv2D(32, (5, 1), activation='relu', input_shape=input_shape_cnn),\n",
    "        MaxPooling2D((2, 1)),\n",
    "        Conv2D(64, (3, 1), activation='relu'),\n",
    "        Flatten(),\n",
    "        Dense(260 * 32, activation='relu')  # Adjusted to match the LSTM input\n",
    "    ])\n",
    "    \n",
    "    cnn_input = Input(shape=input_shape_cnn)\n",
    "    cnn_output = cnn_model(cnn_input)\n",
    "    \n",
    "    # Correctly reshape the CNN output to match LSTM input expectations\n",
    "    timesteps = input_shape_lstm[0]  # This is typically the length of the input sequence\n",
    "    features = 32  # Reduced the features to match the Dense layer output\n",
    "    \n",
    "    lstm_input = Reshape((timesteps, features))(cnn_output)\n",
    "    lstm_output = LSTM(32)(lstm_input)\n",
    "    \n",
    "    output = Dense(num_classes, activation='softmax')(lstm_output)\n",
    "    \n",
    "    model = Model(inputs=cnn_input, outputs=output)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Define the input shape based on your data\n",
    "input_shape_lstm_gru = (segments.shape[1], 1)  # (timesteps, features) for LSTM/GRU\n",
    "input_shape_cnn_resnet = (segments.shape[1], 1, 1)  # (timesteps, features, 1) for CNN/ResNet\n",
    "\n",
    "# Number of classes\n",
    "num_classes = len(valid_labels)\n",
    "\n",
    "# Create the models\n",
    "deeper_cnn_model = create_deeper_cnn(input_shape_cnn_resnet, num_classes)\n",
    "resnet_model = create_resnet(input_shape_cnn_resnet, num_classes)\n",
    "stacked_gru_model = create_stacked_gru(input_shape_lstm_gru, num_classes)\n",
    "vanilla_lstm_model = create_vanilla_lstm(input_shape_lstm_gru, num_classes)\n",
    "stacked_lstm_model = create_stacked_lstm(input_shape_lstm_gru, num_classes)\n",
    "bidirectional_lstm_model = create_bidirectional_lstm(input_shape_lstm_gru, num_classes)\n",
    "cnn_lstm_model = create_cnn_lstm(input_shape_cnn_resnet, input_shape_lstm_gru, num_classes)\n",
    "\n",
    "# Train the models and store history\n",
    "models = [\n",
    "    (deeper_cnn_model, 'Deeper CNN', 50),\n",
    "    (resnet_model, 'ResNet', 50),\n",
    "    (stacked_gru_model, 'Stacked GRU', 50),\n",
    "    (vanilla_lstm_model, 'Vanilla LSTM', 50),\n",
    "    (stacked_lstm_model, 'Stacked LSTM', 50),\n",
    "    (bidirectional_lstm_model, 'Bidirectional LSTM', 50),\n",
    "    (cnn_lstm_model, 'CNN-LSTM', 50)\n",
    "]\n",
    "\n",
    "histories = {}\n",
    "\n",
    "for model, name, epochs in models:\n",
    "    print(f'Training {name}...')\n",
    "    start_time = time.time()\n",
    "    history = model.fit(X_train, y_train, epochs=epochs, validation_data=(X_val, y_val), batch_size=32)\n",
    "    total_training_time = time.time() - start_time\n",
    "    print(f\"Total Training Time for {name}: {total_training_time:.2f} seconds\")\n",
    "    histories[name] = history\n",
    "\n",
    "# Predict using all models\n",
    "y_pred_deeper_cnn = deeper_cnn_model.predict(X_test)\n",
    "y_pred_resnet = resnet_model.predict(X_test)\n",
    "y_pred_stacked_gru = stacked_gru_model.predict(X_test)\n",
    "y_pred_vanilla = vanilla_lstm_model.predict(X_test)\n",
    "y_pred_stacked = stacked_lstm_model.predict(X_test)\n",
    "y_pred_bidirectional = bidirectional_lstm_model.predict(X_test)\n",
    "y_pred_cnn_lstm = cnn_lstm_model.predict(X_test)\n",
    "\n",
    "# Ensemble method - Average predictions from all models\n",
    "y_pred_ensemble = (y_pred_deeper_cnn + y_pred_resnet + y_pred_stacked_gru + \n",
    "                   y_pred_vanilla + y_pred_stacked + y_pred_bidirectional + y_pred_cnn_lstm) / 7\n",
    "y_pred_classes_ensemble = np.argmax(y_pred_ensemble, axis=1)\n",
    "y_test_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Compute the confusion matrix\n",
    "conf_matrix_ensemble = confusion_matrix(y_test_classes, y_pred_classes_ensemble)\n",
    "\n",
    "# Compute the metrics\n",
    "overall_accuracy_ensemble = np.sum(y_pred_classes_ensemble == y_test_classes) / len(y_test_classes)\n",
    "overall_sensitivity_ensemble = recall_score(y_test_classes, y_pred_classes_ensemble, average='macro') * 100\n",
    "overall_specificity_ensemble = (conf_matrix_ensemble[0,0] / (conf_matrix_ensemble[0,0] + conf_matrix_ensemble[0,1])) * 100 if conf_matrix_ensemble.shape[0] > 1 else 0\n",
    "overall_precision_ensemble = precision_score(y_test_classes, y_pred_classes_ensemble, average='macro') * 100\n",
    "overall_fscore_ensemble = f1_score(y_test_classes, y_pred_classes_ensemble, average='macro') * 100\n",
    "\n",
    "# Print the ensemble results\n",
    "print(f\"Results for Ensemble of All Models:\")\n",
    "print(f\"Overall Accuracy: {overall_accuracy_ensemble * 100:.2f}%\")\n",
    "print(f\"Overall Sensitivity: {overall_sensitivity_ensemble:.2f}%\")\n",
    "print(f\"Overall Specificity: {overall_specificity_ensemble:.2f}%\")\n",
    "print(f\"Overall Precision: {overall_precision_ensemble:.2f}%\")\n",
    "print(f\"Overall F-Score: {overall_fscore_ensemble:.2f}%\")\n",
    "\n",
    "# Calculate per-class metrics\n",
    "class_names = label_encoder.inverse_transform(np.arange(num_classes))\n",
    "accuracy_per_class_ensemble = []\n",
    "sensitivity_per_class_ensemble = []\n",
    "specificity_per_class_ensemble = []\n",
    "precision_per_class_ensemble = []\n",
    "f1score_per_class_ensemble = []\n",
    "\n",
    "for i, class_name in enumerate(class_names):\n",
    "    true_positive = conf_matrix_ensemble[i, i]\n",
    "    false_positive = np.sum(conf_matrix_ensemble[:, i]) - true_positive\n",
    "    false_negative = np.sum(conf_matrix_ensemble[i, :]) - true_positive\n",
    "    true_negative = np.sum(conf_matrix_ensemble) - (true_positive + false_positive + false_negative)\n",
    "    \n",
    "    accuracy = (true_positive + true_negative) / np.sum(conf_matrix_ensemble) * 100\n",
    "    sensitivity = true_positive / (true_positive + false_negative) * 100 if (true_positive + false_negative) > 0 else 0\n",
    "    specificity = true_negative / (true_negative + false_positive) * 100 if (true_negative + false_positive) > 0 else 0\n",
    "    precision = true_positive / (true_positive + false_positive) * 100 if (true_positive + false_positive) > 0 else 0\n",
    "    f1score = (2 * precision * sensitivity) / (precision + sensitivity) if (precision + sensitivity) > 0 else 0\n",
    "    \n",
    "    accuracy_per_class_ensemble.append(accuracy)\n",
    "    sensitivity_per_class_ensemble.append(sensitivity)\n",
    "    specificity_per_class_ensemble.append(specificity)\n",
    "    precision_per_class_ensemble.append(precision)\n",
    "    f1score_per_class_ensemble.append(f1score)\n",
    "\n",
    "# Display the ensemble results in a DataFrame\n",
    "performance_df_ensemble = pd.DataFrame({\n",
    "    'Classes': class_names,\n",
    "    'Accuracy (%)': accuracy_per_class_ensemble,\n",
    "    'Sensitivity (%)': sensitivity_per_class_ensemble,\n",
    "    'Specificity (%)': specificity_per_class_ensemble,\n",
    "    'Precision (%)': precision_per_class_ensemble,\n",
    "    'F1 Score (%)': f1score_per_class_ensemble\n",
    "})\n",
    "\n",
    "# Add overall accuracy to match the table\n",
    "performance_df_ensemble['Overall Accuracy (%)'] = overall_accuracy_ensemble * 100\n",
    "\n",
    "print(performance_df_ensemble)\n",
    "\n",
    "# Plot ensemble confusion matrix\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(conf_matrix_ensemble, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title(f'Ensemble Confusion Matrix')\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.show()\n",
    "\n",
    "# Plot accuracy and loss graphs for each model\n",
    "for name, history in histories.items():\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    \n",
    "    # Plot accuracy\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(np.array(history.history['accuracy']) * 100, 'o--', label='Train Accuracy')\n",
    "    plt.plot(np.array(history.history['val_accuracy']) * 100, 'o--', label='Validation Accuracy')\n",
    "    plt.title(f'{name} Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot loss\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'], 'o--', label='Train Loss')\n",
    "    plt.plot(history.history['val_loss'], 'o--', label='Validation Loss')\n",
    "    plt.title(f'{name} Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1400bf30-cb35-48a7-a02c-200fe1da331f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
