{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd9f7fb-7472-4df3-9b93-4f003a7b181a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bs23037\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "C:\\Users\\bs23037\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Deeper CNN...\n",
      "Epoch 1/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 25ms/step - accuracy: 0.8878 - loss: 0.3914 - val_accuracy: 0.9735 - val_loss: 0.1174\n",
      "Epoch 2/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 25ms/step - accuracy: 0.9668 - loss: 0.1323 - val_accuracy: 0.9759 - val_loss: 0.0932\n",
      "Epoch 3/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 26ms/step - accuracy: 0.9750 - loss: 0.0943 - val_accuracy: 0.9794 - val_loss: 0.0725\n",
      "Epoch 4/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 29ms/step - accuracy: 0.9790 - loss: 0.0781 - val_accuracy: 0.9849 - val_loss: 0.0527\n",
      "Epoch 5/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 29ms/step - accuracy: 0.9827 - loss: 0.0656 - val_accuracy: 0.9864 - val_loss: 0.0505\n",
      "Epoch 6/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 29ms/step - accuracy: 0.9844 - loss: 0.0568 - val_accuracy: 0.9868 - val_loss: 0.0508\n",
      "Epoch 7/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 29ms/step - accuracy: 0.9864 - loss: 0.0504 - val_accuracy: 0.9880 - val_loss: 0.0410\n",
      "Epoch 8/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 29ms/step - accuracy: 0.9884 - loss: 0.0421 - val_accuracy: 0.9880 - val_loss: 0.0383\n",
      "Epoch 9/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 29ms/step - accuracy: 0.9890 - loss: 0.0402 - val_accuracy: 0.9895 - val_loss: 0.0343\n",
      "Epoch 10/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 29ms/step - accuracy: 0.9900 - loss: 0.0358 - val_accuracy: 0.9883 - val_loss: 0.0388\n",
      "Epoch 11/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 29ms/step - accuracy: 0.9907 - loss: 0.0330 - val_accuracy: 0.9893 - val_loss: 0.0370\n",
      "Epoch 12/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 29ms/step - accuracy: 0.9916 - loss: 0.0285 - val_accuracy: 0.9888 - val_loss: 0.0383\n",
      "Epoch 13/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 30ms/step - accuracy: 0.9922 - loss: 0.0271 - val_accuracy: 0.9919 - val_loss: 0.0278\n",
      "Epoch 14/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 29ms/step - accuracy: 0.9930 - loss: 0.0254 - val_accuracy: 0.9912 - val_loss: 0.0313\n",
      "Epoch 15/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 30ms/step - accuracy: 0.9931 - loss: 0.0233 - val_accuracy: 0.9734 - val_loss: 0.0817\n",
      "Epoch 16/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 29ms/step - accuracy: 0.9933 - loss: 0.0228 - val_accuracy: 0.9922 - val_loss: 0.0271\n",
      "Epoch 17/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 30ms/step - accuracy: 0.9937 - loss: 0.0211 - val_accuracy: 0.9908 - val_loss: 0.0354\n",
      "Epoch 18/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 30ms/step - accuracy: 0.9947 - loss: 0.0180 - val_accuracy: 0.9903 - val_loss: 0.0403\n",
      "Epoch 19/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 30ms/step - accuracy: 0.9943 - loss: 0.0188 - val_accuracy: 0.9908 - val_loss: 0.0331\n",
      "Epoch 20/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 30ms/step - accuracy: 0.9949 - loss: 0.0158 - val_accuracy: 0.9915 - val_loss: 0.0312\n",
      "Epoch 21/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 30ms/step - accuracy: 0.9954 - loss: 0.0147 - val_accuracy: 0.9921 - val_loss: 0.0300\n",
      "Epoch 22/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 30ms/step - accuracy: 0.9948 - loss: 0.0159 - val_accuracy: 0.9920 - val_loss: 0.0296\n",
      "Epoch 23/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 30ms/step - accuracy: 0.9958 - loss: 0.0124 - val_accuracy: 0.9924 - val_loss: 0.0272\n",
      "Epoch 24/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 30ms/step - accuracy: 0.9963 - loss: 0.0125 - val_accuracy: 0.9924 - val_loss: 0.0283\n",
      "Epoch 25/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 30ms/step - accuracy: 0.9959 - loss: 0.0131 - val_accuracy: 0.9914 - val_loss: 0.0312\n",
      "Epoch 26/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 30ms/step - accuracy: 0.9962 - loss: 0.0111 - val_accuracy: 0.9918 - val_loss: 0.0312\n",
      "Epoch 27/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 30ms/step - accuracy: 0.9959 - loss: 0.0116 - val_accuracy: 0.9920 - val_loss: 0.0307\n",
      "Epoch 28/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 30ms/step - accuracy: 0.9968 - loss: 0.0101 - val_accuracy: 0.9900 - val_loss: 0.0486\n",
      "Epoch 29/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 30ms/step - accuracy: 0.9967 - loss: 0.0110 - val_accuracy: 0.9914 - val_loss: 0.0313\n",
      "Epoch 30/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 30ms/step - accuracy: 0.9971 - loss: 0.0097 - val_accuracy: 0.9791 - val_loss: 0.0657\n",
      "Epoch 31/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 31ms/step - accuracy: 0.9967 - loss: 0.0100 - val_accuracy: 0.9925 - val_loss: 0.0279\n",
      "Epoch 32/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 31ms/step - accuracy: 0.9973 - loss: 0.0086 - val_accuracy: 0.9907 - val_loss: 0.0414\n",
      "Epoch 33/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 31ms/step - accuracy: 0.9971 - loss: 0.0087 - val_accuracy: 0.9916 - val_loss: 0.0383\n",
      "Epoch 34/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 31ms/step - accuracy: 0.9971 - loss: 0.0078 - val_accuracy: 0.9913 - val_loss: 0.0410\n",
      "Epoch 35/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 31ms/step - accuracy: 0.9975 - loss: 0.0075 - val_accuracy: 0.9920 - val_loss: 0.0349\n",
      "Epoch 36/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 31ms/step - accuracy: 0.9982 - loss: 0.0061 - val_accuracy: 0.9927 - val_loss: 0.0353\n",
      "Epoch 37/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 31ms/step - accuracy: 0.9972 - loss: 0.0079 - val_accuracy: 0.9925 - val_loss: 0.0328\n",
      "Epoch 38/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 31ms/step - accuracy: 0.9981 - loss: 0.0058 - val_accuracy: 0.9921 - val_loss: 0.0345\n",
      "Epoch 39/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 31ms/step - accuracy: 0.9981 - loss: 0.0058 - val_accuracy: 0.9902 - val_loss: 0.0468\n",
      "Epoch 40/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 31ms/step - accuracy: 0.9980 - loss: 0.0063 - val_accuracy: 0.9915 - val_loss: 0.0428\n",
      "Epoch 41/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 31ms/step - accuracy: 0.9978 - loss: 0.0058 - val_accuracy: 0.9901 - val_loss: 0.0434\n",
      "Epoch 42/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 32ms/step - accuracy: 0.9982 - loss: 0.0056 - val_accuracy: 0.9923 - val_loss: 0.0428\n",
      "Epoch 43/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 32ms/step - accuracy: 0.9982 - loss: 0.0054 - val_accuracy: 0.9257 - val_loss: 0.2646\n",
      "Epoch 44/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 33ms/step - accuracy: 0.9983 - loss: 0.0054 - val_accuracy: 0.9915 - val_loss: 0.0391\n",
      "Epoch 45/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 33ms/step - accuracy: 0.9985 - loss: 0.0049 - val_accuracy: 0.9906 - val_loss: 0.0481\n",
      "Epoch 46/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 33ms/step - accuracy: 0.9985 - loss: 0.0051 - val_accuracy: 0.9921 - val_loss: 0.0344\n",
      "Epoch 47/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 33ms/step - accuracy: 0.9985 - loss: 0.0048 - val_accuracy: 0.9918 - val_loss: 0.0422\n",
      "Epoch 48/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 33ms/step - accuracy: 0.9983 - loss: 0.0055 - val_accuracy: 0.9912 - val_loss: 0.0381\n",
      "Epoch 49/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 33ms/step - accuracy: 0.9985 - loss: 0.0046 - val_accuracy: 0.9923 - val_loss: 0.0372\n",
      "Epoch 50/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 32ms/step - accuracy: 0.9989 - loss: 0.0038 - val_accuracy: 0.9921 - val_loss: 0.0353\n",
      "Total Training Time for Deeper CNN: 3781.57 seconds\n",
      "Training ResNet...\n",
      "Epoch 1/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 30ms/step - accuracy: 0.9056 - loss: 0.3137 - val_accuracy: 0.9750 - val_loss: 0.0923\n",
      "Epoch 2/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 30ms/step - accuracy: 0.9764 - loss: 0.0849 - val_accuracy: 0.9831 - val_loss: 0.0639\n",
      "Epoch 3/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 29ms/step - accuracy: 0.9829 - loss: 0.0595 - val_accuracy: 0.9792 - val_loss: 0.0701\n",
      "Epoch 4/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 30ms/step - accuracy: 0.9875 - loss: 0.0461 - val_accuracy: 0.9855 - val_loss: 0.0510\n",
      "Epoch 5/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 30ms/step - accuracy: 0.9891 - loss: 0.0368 - val_accuracy: 0.9908 - val_loss: 0.0339\n",
      "Epoch 6/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 31ms/step - accuracy: 0.9908 - loss: 0.0320 - val_accuracy: 0.9885 - val_loss: 0.0400\n",
      "Epoch 7/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 31ms/step - accuracy: 0.9918 - loss: 0.0284 - val_accuracy: 0.9907 - val_loss: 0.0321\n",
      "Epoch 8/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 30ms/step - accuracy: 0.9926 - loss: 0.0236 - val_accuracy: 0.9891 - val_loss: 0.0417\n",
      "Epoch 9/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 30ms/step - accuracy: 0.9934 - loss: 0.0218 - val_accuracy: 0.9918 - val_loss: 0.0275\n",
      "Epoch 10/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 30ms/step - accuracy: 0.9936 - loss: 0.0209 - val_accuracy: 0.9915 - val_loss: 0.0311\n",
      "Epoch 11/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 30ms/step - accuracy: 0.9938 - loss: 0.0192 - val_accuracy: 0.9925 - val_loss: 0.0271\n",
      "Epoch 12/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 30ms/step - accuracy: 0.9955 - loss: 0.0150 - val_accuracy: 0.9915 - val_loss: 0.0286\n",
      "Epoch 13/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 30ms/step - accuracy: 0.9957 - loss: 0.0141 - val_accuracy: 0.9918 - val_loss: 0.0317\n",
      "Epoch 14/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 30ms/step - accuracy: 0.9960 - loss: 0.0128 - val_accuracy: 0.9917 - val_loss: 0.0295\n",
      "Epoch 15/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 30ms/step - accuracy: 0.9961 - loss: 0.0128 - val_accuracy: 0.9861 - val_loss: 0.0491\n",
      "Epoch 16/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 30ms/step - accuracy: 0.9963 - loss: 0.0111 - val_accuracy: 0.9916 - val_loss: 0.0299\n",
      "Epoch 17/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 30ms/step - accuracy: 0.9972 - loss: 0.0090 - val_accuracy: 0.9935 - val_loss: 0.0227\n",
      "Epoch 18/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 30ms/step - accuracy: 0.9972 - loss: 0.0085 - val_accuracy: 0.9929 - val_loss: 0.0266\n",
      "Epoch 19/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 30ms/step - accuracy: 0.9975 - loss: 0.0079 - val_accuracy: 0.8996 - val_loss: 0.3118\n",
      "Epoch 20/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 30ms/step - accuracy: 0.9978 - loss: 0.0071 - val_accuracy: 0.9912 - val_loss: 0.0326\n",
      "Epoch 21/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 30ms/step - accuracy: 0.9976 - loss: 0.0075 - val_accuracy: 0.9931 - val_loss: 0.0274\n",
      "Epoch 22/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 30ms/step - accuracy: 0.9976 - loss: 0.0066 - val_accuracy: 0.9946 - val_loss: 0.0230\n",
      "Epoch 23/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 30ms/step - accuracy: 0.9981 - loss: 0.0059 - val_accuracy: 0.9917 - val_loss: 0.0307\n",
      "Epoch 24/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 30ms/step - accuracy: 0.9984 - loss: 0.0051 - val_accuracy: 0.9921 - val_loss: 0.0330\n",
      "Epoch 25/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 30ms/step - accuracy: 0.9985 - loss: 0.0048 - val_accuracy: 0.9939 - val_loss: 0.0251\n",
      "Epoch 26/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 30ms/step - accuracy: 0.9987 - loss: 0.0040 - val_accuracy: 0.9917 - val_loss: 0.0347\n",
      "Epoch 27/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 30ms/step - accuracy: 0.9979 - loss: 0.0060 - val_accuracy: 0.9943 - val_loss: 0.0247\n",
      "Epoch 28/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 30ms/step - accuracy: 0.9986 - loss: 0.0040 - val_accuracy: 0.9925 - val_loss: 0.0315\n",
      "Epoch 29/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 31ms/step - accuracy: 0.9988 - loss: 0.0039 - val_accuracy: 0.9931 - val_loss: 0.0304\n",
      "Epoch 30/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 31ms/step - accuracy: 0.9992 - loss: 0.0031 - val_accuracy: 0.9937 - val_loss: 0.0268\n",
      "Epoch 31/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 31ms/step - accuracy: 0.9985 - loss: 0.0042 - val_accuracy: 0.9924 - val_loss: 0.0321\n",
      "Epoch 32/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 31ms/step - accuracy: 0.9986 - loss: 0.0041 - val_accuracy: 0.9916 - val_loss: 0.0359\n",
      "Epoch 33/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 31ms/step - accuracy: 0.9985 - loss: 0.0043 - val_accuracy: 0.9936 - val_loss: 0.0285\n",
      "Epoch 34/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 31ms/step - accuracy: 0.9987 - loss: 0.0037 - val_accuracy: 0.9933 - val_loss: 0.0268\n",
      "Epoch 35/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 31ms/step - accuracy: 0.9986 - loss: 0.0042 - val_accuracy: 0.9919 - val_loss: 0.0362\n",
      "Epoch 36/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 31ms/step - accuracy: 0.9991 - loss: 0.0030 - val_accuracy: 0.9945 - val_loss: 0.0267\n",
      "Epoch 37/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 31ms/step - accuracy: 0.9989 - loss: 0.0037 - val_accuracy: 0.9944 - val_loss: 0.0287\n",
      "Epoch 38/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 31ms/step - accuracy: 0.9987 - loss: 0.0032 - val_accuracy: 0.9935 - val_loss: 0.0326\n",
      "Epoch 39/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 31ms/step - accuracy: 0.9989 - loss: 0.0032 - val_accuracy: 0.9943 - val_loss: 0.0254\n",
      "Epoch 40/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 31ms/step - accuracy: 0.9992 - loss: 0.0027 - val_accuracy: 0.9939 - val_loss: 0.0261\n",
      "Epoch 41/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 31ms/step - accuracy: 0.9991 - loss: 0.0029 - val_accuracy: 0.9894 - val_loss: 0.0425\n",
      "Epoch 42/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 31ms/step - accuracy: 0.9988 - loss: 0.0036 - val_accuracy: 0.9943 - val_loss: 0.0273\n",
      "Epoch 43/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 31ms/step - accuracy: 0.9992 - loss: 0.0022 - val_accuracy: 0.9954 - val_loss: 0.0219\n",
      "Epoch 44/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 31ms/step - accuracy: 0.9992 - loss: 0.0024 - val_accuracy: 0.9948 - val_loss: 0.0255\n",
      "Epoch 45/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 32ms/step - accuracy: 0.9992 - loss: 0.0025 - val_accuracy: 0.9899 - val_loss: 0.0421\n",
      "Epoch 46/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 31ms/step - accuracy: 0.9995 - loss: 0.0020 - val_accuracy: 0.9946 - val_loss: 0.0275\n",
      "Epoch 47/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 31ms/step - accuracy: 0.9989 - loss: 0.0028 - val_accuracy: 0.9946 - val_loss: 0.0243\n",
      "Epoch 48/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 32ms/step - accuracy: 0.9995 - loss: 0.0017 - val_accuracy: 0.9938 - val_loss: 0.0313\n",
      "Epoch 49/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 31ms/step - accuracy: 0.9992 - loss: 0.0024 - val_accuracy: 0.9942 - val_loss: 0.0316\n",
      "Epoch 50/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 31ms/step - accuracy: 0.9987 - loss: 0.0042 - val_accuracy: 0.9938 - val_loss: 0.0320\n",
      "Total Training Time for ResNet: 3808.86 seconds\n",
      "Training Stacked GRU...\n",
      "Epoch 1/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m173s\u001b[0m 68ms/step - accuracy: 0.7130 - loss: 1.0934 - val_accuracy: 0.7533 - val_loss: 0.8498\n",
      "Epoch 2/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 68ms/step - accuracy: 0.7512 - loss: 0.8783 - val_accuracy: 0.7533 - val_loss: 0.8250\n",
      "Epoch 3/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 68ms/step - accuracy: 0.7508 - loss: 0.8542 - val_accuracy: 0.7533 - val_loss: 0.7999\n",
      "Epoch 4/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 68ms/step - accuracy: 0.7521 - loss: 0.8083 - val_accuracy: 0.7533 - val_loss: 0.7058\n",
      "Epoch 5/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 68ms/step - accuracy: 0.7546 - loss: 0.6913 - val_accuracy: 0.7931 - val_loss: 0.5766\n",
      "Epoch 6/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 68ms/step - accuracy: 0.8022 - loss: 0.5802 - val_accuracy: 0.8460 - val_loss: 0.4711\n",
      "Epoch 7/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 68ms/step - accuracy: 0.8406 - loss: 0.4868 - val_accuracy: 0.8709 - val_loss: 0.4056\n",
      "Epoch 8/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 68ms/step - accuracy: 0.8664 - loss: 0.4219 - val_accuracy: 0.8904 - val_loss: 0.3493\n",
      "Epoch 9/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 68ms/step - accuracy: 0.8819 - loss: 0.3767 - val_accuracy: 0.9005 - val_loss: 0.3198\n",
      "Epoch 10/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 68ms/step - accuracy: 0.8936 - loss: 0.3424 - val_accuracy: 0.9091 - val_loss: 0.2840\n",
      "Epoch 11/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 68ms/step - accuracy: 0.9023 - loss: 0.3238 - val_accuracy: 0.9212 - val_loss: 0.2606\n",
      "Epoch 12/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 68ms/step - accuracy: 0.9117 - loss: 0.2990 - val_accuracy: 0.9202 - val_loss: 0.2513\n",
      "Epoch 13/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 68ms/step - accuracy: 0.9196 - loss: 0.2799 - val_accuracy: 0.9333 - val_loss: 0.2255\n",
      "Epoch 14/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 69ms/step - accuracy: 0.9234 - loss: 0.2667 - val_accuracy: 0.9409 - val_loss: 0.2093\n",
      "Epoch 15/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 68ms/step - accuracy: 0.9301 - loss: 0.2555 - val_accuracy: 0.9447 - val_loss: 0.2004\n",
      "Epoch 16/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 68ms/step - accuracy: 0.9364 - loss: 0.2352 - val_accuracy: 0.9492 - val_loss: 0.1897\n",
      "Epoch 17/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 68ms/step - accuracy: 0.9391 - loss: 0.2316 - val_accuracy: 0.9510 - val_loss: 0.1828\n",
      "Epoch 18/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 68ms/step - accuracy: 0.9425 - loss: 0.2216 - val_accuracy: 0.9492 - val_loss: 0.1881\n",
      "Epoch 19/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 68ms/step - accuracy: 0.9455 - loss: 0.2123 - val_accuracy: 0.9550 - val_loss: 0.1692\n",
      "Epoch 20/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 68ms/step - accuracy: 0.9491 - loss: 0.2067 - val_accuracy: 0.9561 - val_loss: 0.1662\n",
      "Epoch 21/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 68ms/step - accuracy: 0.9500 - loss: 0.1960 - val_accuracy: 0.9590 - val_loss: 0.1580\n",
      "Epoch 22/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 68ms/step - accuracy: 0.9537 - loss: 0.1876 - val_accuracy: 0.9566 - val_loss: 0.1632\n",
      "Epoch 23/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 68ms/step - accuracy: 0.9560 - loss: 0.1789 - val_accuracy: 0.9620 - val_loss: 0.1478\n",
      "Epoch 24/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 68ms/step - accuracy: 0.9559 - loss: 0.1787 - val_accuracy: 0.9632 - val_loss: 0.1438\n",
      "Epoch 25/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 68ms/step - accuracy: 0.9581 - loss: 0.1694 - val_accuracy: 0.9659 - val_loss: 0.1347\n",
      "Epoch 26/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 68ms/step - accuracy: 0.9598 - loss: 0.1672 - val_accuracy: 0.9662 - val_loss: 0.1352\n",
      "Epoch 27/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 68ms/step - accuracy: 0.9599 - loss: 0.1665 - val_accuracy: 0.9654 - val_loss: 0.1383\n",
      "Epoch 28/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 68ms/step - accuracy: 0.9624 - loss: 0.1591 - val_accuracy: 0.9659 - val_loss: 0.1292\n",
      "Epoch 29/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 69ms/step - accuracy: 0.9627 - loss: 0.1572 - val_accuracy: 0.9674 - val_loss: 0.1249\n",
      "Epoch 30/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 68ms/step - accuracy: 0.9625 - loss: 0.1529 - val_accuracy: 0.9664 - val_loss: 0.1327\n",
      "Epoch 31/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 69ms/step - accuracy: 0.9645 - loss: 0.1480 - val_accuracy: 0.9696 - val_loss: 0.1237\n",
      "Epoch 32/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 68ms/step - accuracy: 0.9635 - loss: 0.1516 - val_accuracy: 0.9710 - val_loss: 0.1156\n",
      "Epoch 33/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 68ms/step - accuracy: 0.9642 - loss: 0.1439 - val_accuracy: 0.9694 - val_loss: 0.1170\n",
      "Epoch 34/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 68ms/step - accuracy: 0.9654 - loss: 0.1422 - val_accuracy: 0.9598 - val_loss: 0.1448\n",
      "Epoch 35/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 70ms/step - accuracy: 0.9662 - loss: 0.1402 - val_accuracy: 0.9706 - val_loss: 0.1142\n",
      "Epoch 36/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m171s\u001b[0m 69ms/step - accuracy: 0.9662 - loss: 0.1412 - val_accuracy: 0.9692 - val_loss: 0.1151\n",
      "Epoch 37/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m172s\u001b[0m 69ms/step - accuracy: 0.9677 - loss: 0.1334 - val_accuracy: 0.9681 - val_loss: 0.1240\n",
      "Epoch 38/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 68ms/step - accuracy: 0.9680 - loss: 0.1347 - val_accuracy: 0.9734 - val_loss: 0.1083\n",
      "Epoch 39/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 68ms/step - accuracy: 0.9682 - loss: 0.1294 - val_accuracy: 0.9712 - val_loss: 0.1116\n",
      "Epoch 40/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 68ms/step - accuracy: 0.9682 - loss: 0.1280 - val_accuracy: 0.9667 - val_loss: 0.1201\n",
      "Epoch 41/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 68ms/step - accuracy: 0.9685 - loss: 0.1244 - val_accuracy: 0.9728 - val_loss: 0.1029\n",
      "Epoch 42/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 68ms/step - accuracy: 0.9690 - loss: 0.1265 - val_accuracy: 0.9729 - val_loss: 0.0993\n",
      "Epoch 43/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 68ms/step - accuracy: 0.9699 - loss: 0.1246 - val_accuracy: 0.9739 - val_loss: 0.0989\n",
      "Epoch 44/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m169s\u001b[0m 68ms/step - accuracy: 0.9704 - loss: 0.1205 - val_accuracy: 0.9725 - val_loss: 0.1041\n",
      "Epoch 45/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 68ms/step - accuracy: 0.9698 - loss: 0.1227 - val_accuracy: 0.9732 - val_loss: 0.1024\n",
      "Epoch 46/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 68ms/step - accuracy: 0.9715 - loss: 0.1153 - val_accuracy: 0.9733 - val_loss: 0.0976\n",
      "Epoch 47/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 68ms/step - accuracy: 0.9700 - loss: 0.1172 - val_accuracy: 0.9752 - val_loss: 0.0979\n",
      "Epoch 48/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 68ms/step - accuracy: 0.9693 - loss: 0.1222 - val_accuracy: 0.9758 - val_loss: 0.0953\n",
      "Epoch 49/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 68ms/step - accuracy: 0.9717 - loss: 0.1150 - val_accuracy: 0.9756 - val_loss: 0.0978\n",
      "Epoch 50/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m170s\u001b[0m 68ms/step - accuracy: 0.9707 - loss: 0.1186 - val_accuracy: 0.9657 - val_loss: 0.1305\n",
      "Total Training Time for Stacked GRU: 8537.33 seconds\n",
      "Training CNN-LSTM...\n",
      "Epoch 1/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1320s\u001b[0m 527ms/step - accuracy: 0.8821 - loss: 0.4386 - val_accuracy: 0.9737 - val_loss: 0.1068\n",
      "Epoch 2/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1320s\u001b[0m 528ms/step - accuracy: 0.9752 - loss: 0.0989 - val_accuracy: 0.9821 - val_loss: 0.0730\n",
      "Epoch 3/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1327s\u001b[0m 531ms/step - accuracy: 0.9825 - loss: 0.0727 - val_accuracy: 0.9849 - val_loss: 0.0613\n",
      "Epoch 4/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1321s\u001b[0m 528ms/step - accuracy: 0.9855 - loss: 0.0590 - val_accuracy: 0.9841 - val_loss: 0.0599\n",
      "Epoch 5/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1320s\u001b[0m 528ms/step - accuracy: 0.9881 - loss: 0.0448 - val_accuracy: 0.9866 - val_loss: 0.0485\n",
      "Epoch 6/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1320s\u001b[0m 528ms/step - accuracy: 0.9883 - loss: 0.0432 - val_accuracy: 0.9874 - val_loss: 0.0448\n",
      "Epoch 7/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1320s\u001b[0m 528ms/step - accuracy: 0.9903 - loss: 0.0375 - val_accuracy: 0.9905 - val_loss: 0.0387\n",
      "Epoch 8/50\n",
      "\u001b[1m2501/2501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1321s\u001b[0m 528ms/step - accuracy: 0.9911 - loss: 0.0349 - val_accuracy: 0.9897 - val_loss: 0.0380\n",
      "Epoch 9/50\n",
      "\u001b[1m 976/2501\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m13:18\u001b[0m 524ms/step - accuracy: 0.9920 - loss: 0.0288"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import wfdb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, GRU, Reshape, Add, Input, Flatten, LSTM, GlobalAveragePooling2D, Dropout, BatchNormalization\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "# Define the path to the extracted dataset\n",
    "data_path = 'M:\\Dissertation\\mit-bih-arrhythmia-database-1.0.0-20240722T094228Z-001\\mit-bih-arrhythmia-database-1.0.0'\n",
    "\n",
    "# Function to load a record and preprocess\n",
    "def load_and_preprocess(record):\n",
    "    signal, fields = wfdb.rdsamp(os.path.join(data_path, record))\n",
    "    annotation = wfdb.rdann(os.path.join(data_path, record), 'atr')\n",
    "    \n",
    "    # Use only one channel (e.g., channel 0)\n",
    "    signal = signal[:, 0].reshape(-1, 1)\n",
    "    \n",
    "    # Segment the signal\n",
    "    segments = []\n",
    "    labels = []\n",
    "    for i in range(len(annotation.sample)):\n",
    "        if annotation.sample[i] - 99 > 0 and annotation.sample[i] + 160 < len(signal):\n",
    "            segments.append(signal[annotation.sample[i] - 99 : annotation.sample[i] + 161])\n",
    "            labels.append(annotation.symbol[i])\n",
    "    \n",
    "    return np.array(segments), np.array(labels)\n",
    "\n",
    "# Function to load and preprocess all records in the dataset\n",
    "def load_and_preprocess_all_records(data_path):\n",
    "    all_segments = []\n",
    "    all_labels = []\n",
    "    \n",
    "    for record in os.listdir(data_path):\n",
    "        if record.endswith('.dat'):\n",
    "            record_name = record[:-4]  # Remove the file extension\n",
    "            segments, labels = load_and_preprocess(record_name)\n",
    "            all_segments.append(segments)\n",
    "            all_labels.append(labels)\n",
    "    \n",
    "    # Concatenate all segments and labels\n",
    "    all_segments = np.vstack(all_segments)\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "    \n",
    "    return all_segments, all_labels\n",
    "\n",
    "# Load and preprocess the entire dataset\n",
    "segments, labels = load_and_preprocess_all_records(data_path)\n",
    "\n",
    "# Filter out unwanted labels (keeping only certain labels, e.g., 'N', 'L', 'R', 'A', 'V')\n",
    "valid_labels = ['N', 'L', 'R', 'A', 'V']\n",
    "mask = np.isin(labels, valid_labels)\n",
    "segments = segments[mask]\n",
    "labels = labels[mask]\n",
    "\n",
    "# Reshape segments to fit the model's expected input shape\n",
    "segments = segments.reshape(segments.shape[0], segments.shape[1], 1, 1)\n",
    "\n",
    "# Encode the labels\n",
    "label_encoder = LabelEncoder()\n",
    "labels_encoded = label_encoder.fit_transform(labels)\n",
    "\n",
    "# Convert labels to categorical format\n",
    "labels_categorical = tf.keras.utils.to_categorical(labels_encoded)\n",
    "\n",
    "# Split the data into training, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(segments, labels_categorical, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# 1. Deeper CNN Model with Regularization and Batch Normalization\n",
    "def create_deeper_cnn(input_shape, num_classes):\n",
    "    model = Sequential([\n",
    "        Conv2D(64, (5, 1), activation='relu', input_shape=input_shape),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2, 1)),\n",
    "        Conv2D(128, (3, 1), activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2, 1)),\n",
    "        Conv2D(256, (3, 1), activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D((2, 1)),\n",
    "        Conv2D(512, (3, 1), activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        GlobalAveragePooling2D(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# 2. ResNet-like Model with Regularization\n",
    "def create_resnet(input_shape, num_classes):\n",
    "    def residual_block(x, filters):\n",
    "        shortcut = x\n",
    "        x = Conv2D(filters, (3, 1), activation='relu', padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Conv2D(filters, (3, 1), activation='relu', padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        \n",
    "        # Adjust the shortcut to have the same number of filters as x\n",
    "        shortcut = Conv2D(filters, (1, 1), activation='linear', padding='same')(shortcut)\n",
    "        x = Add()([x, shortcut])\n",
    "        return x\n",
    "\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = Conv2D(64, (3, 1), activation='relu', padding='same')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D((2, 1))(x)\n",
    "    x = residual_block(x, 64)\n",
    "    x = MaxPooling2D((2, 1))(x)\n",
    "    x = residual_block(x, 128)\n",
    "    x = MaxPooling2D((2, 1))(x)\n",
    "    x = residual_block(x, 256)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    Dropout(0.5)(x)\n",
    "    outputs = Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs, outputs)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# 3. Stacked GRU Model with Regularization\n",
    "def create_stacked_gru(input_shape, num_classes):\n",
    "    model = Sequential([\n",
    "        GRU(32, return_sequences=True, input_shape=input_shape),\n",
    "        GRU(32),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# 4. CNN-LSTM Model with Regularization\n",
    "def create_cnn_lstm(input_shape_cnn, input_shape_lstm, num_classes):\n",
    "    cnn_model = Sequential([\n",
    "        Conv2D(32, (5, 1), activation='relu', input_shape=input_shape_cnn),\n",
    "        MaxPooling2D((2, 1)),\n",
    "        Conv2D(64, (3, 1), activation='relu'),\n",
    "        Flatten(),\n",
    "        Dense(260 * 32, activation='relu')  # Adjusted to match the LSTM input\n",
    "    ])\n",
    "    \n",
    "    cnn_input = Input(shape=input_shape_cnn)\n",
    "    cnn_output = cnn_model(cnn_input)\n",
    "    \n",
    "    # Correctly reshape the CNN output to match LSTM input expectations\n",
    "    timesteps = input_shape_lstm[0]  # This is typically the length of the input sequence\n",
    "    features = 32  # Reduced the features to match the Dense layer output\n",
    "    \n",
    "    lstm_input = Reshape((timesteps, features))(cnn_output)\n",
    "    lstm_output = LSTM(32)(lstm_input)\n",
    "    \n",
    "    output = Dense(num_classes, activation='softmax')(lstm_output)\n",
    "    \n",
    "    model = Model(inputs=cnn_input, outputs=output)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Define the input shape based on your data\n",
    "input_shape_lstm_gru = (segments.shape[1], 1)  # (timesteps, features) for LSTM/GRU\n",
    "input_shape_cnn_resnet = (segments.shape[1], 1, 1)  # (timesteps, features, 1) for CNN/ResNet\n",
    "\n",
    "# Number of classes\n",
    "num_classes = len(valid_labels)\n",
    "\n",
    "# Create the models\n",
    "deeper_cnn_model = create_deeper_cnn(input_shape_cnn_resnet, num_classes)\n",
    "resnet_model = create_resnet(input_shape_cnn_resnet, num_classes)\n",
    "stacked_gru_model = create_stacked_gru(input_shape_lstm_gru, num_classes)\n",
    "cnn_lstm_model = create_cnn_lstm(input_shape_cnn_resnet, input_shape_lstm_gru, num_classes)\n",
    "\n",
    "# Train the models and store history\n",
    "models = [\n",
    "    (deeper_cnn_model, 'Deeper CNN', 50),\n",
    "    (resnet_model, 'ResNet', 50),\n",
    "    (stacked_gru_model, 'Stacked GRU', 50),\n",
    "    (cnn_lstm_model, 'CNN-LSTM', 50)\n",
    "]\n",
    "\n",
    "histories = {}\n",
    "\n",
    "for model, name, epochs in models:\n",
    "    print(f'Training {name}...')\n",
    "    start_time = time.time()\n",
    "    history = model.fit(X_train, y_train, epochs=epochs, validation_data=(X_val, y_val), batch_size=32)\n",
    "    total_training_time = time.time() - start_time\n",
    "    print(f\"Total Training Time for {name}: {total_training_time:.2f} seconds\")\n",
    "    histories[name] = history\n",
    "\n",
    "# Predict using all models\n",
    "y_pred_deeper_cnn = deeper_cnn_model.predict(X_test)\n",
    "y_pred_resnet = resnet_model.predict(X_test)\n",
    "y_pred_stacked_gru = stacked_gru_model.predict(X_test)\n",
    "y_pred_cnn_lstm = cnn_lstm_model.predict(X_test)\n",
    "\n",
    "# Ensemble method - Average predictions from all models\n",
    "y_pred_ensemble = (y_pred_deeper_cnn + y_pred_resnet + y_pred_stacked_gru + \n",
    "                   y_pred_cnn_lstm) / 4\n",
    "y_pred_classes_ensemble = np.argmax(y_pred_ensemble, axis=1)\n",
    "y_test_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Compute the confusion matrix\n",
    "conf_matrix_ensemble = confusion_matrix(y_test_classes, y_pred_classes_ensemble)\n",
    "\n",
    "# Compute the metrics\n",
    "overall_accuracy_ensemble = np.sum(y_pred_classes_ensemble == y_test_classes) / len(y_test_classes)\n",
    "overall_sensitivity_ensemble = recall_score(y_test_classes, y_pred_classes_ensemble, average='macro') * 100\n",
    "overall_specificity_ensemble = (conf_matrix_ensemble[0,0] / (conf_matrix_ensemble[0,0] + conf_matrix_ensemble[0,1])) * 100 if conf_matrix_ensemble.shape[0] > 1 else 0\n",
    "overall_precision_ensemble = precision_score(y_test_classes, y_pred_classes_ensemble, average='macro') * 100\n",
    "overall_fscore_ensemble = f1_score(y_test_classes, y_pred_classes_ensemble, average='macro') * 100\n",
    "\n",
    "# Print the ensemble results\n",
    "print(f\"Results for Ensemble of All Models:\")\n",
    "print(f\"Overall Accuracy: {overall_accuracy_ensemble * 100:.2f}%\")\n",
    "print(f\"Overall Sensitivity: {overall_sensitivity_ensemble:.2f}%\")\n",
    "print(f\"Overall Specificity: {overall_specificity_ensemble:.2f}%\")\n",
    "print(f\"Overall Precision: {overall_precision_ensemble:.2f}%\")\n",
    "print(f\"Overall F-Score: {overall_fscore_ensemble:.2f}%\")\n",
    "\n",
    "# Calculate per-class metrics\n",
    "class_names = label_encoder.inverse_transform(np.arange(num_classes))\n",
    "accuracy_per_class_ensemble = []\n",
    "sensitivity_per_class_ensemble = []\n",
    "specificity_per_class_ensemble = []\n",
    "precision_per_class_ensemble = []\n",
    "f1score_per_class_ensemble = []\n",
    "\n",
    "for i, class_name in enumerate(class_names):\n",
    "    true_positive = conf_matrix_ensemble[i, i]\n",
    "    false_positive = np.sum(conf_matrix_ensemble[:, i]) - true_positive\n",
    "    false_negative = np.sum(conf_matrix_ensemble[i, :]) - true_positive\n",
    "    true_negative = np.sum(conf_matrix_ensemble) - (true_positive + false_positive + false_negative)\n",
    "    \n",
    "    accuracy = (true_positive + true_negative) / np.sum(conf_matrix_ensemble) * 100\n",
    "    sensitivity = true_positive / (true_positive + false_negative) * 100 if (true_positive + false_negative) > 0 else 0\n",
    "    specificity = true_negative / (true_negative + false_positive) * 100 if (true_negative + false_positive) > 0 else 0\n",
    "    precision = true_positive / (true_positive + false_positive) * 100 if (true_positive + false_positive) > 0 else 0\n",
    "    f1score = (2 * precision * sensitivity) / (precision + sensitivity) if (precision + sensitivity) > 0 else 0\n",
    "    \n",
    "    accuracy_per_class_ensemble.append(accuracy)\n",
    "    sensitivity_per_class_ensemble.append(sensitivity)\n",
    "    specificity_per_class_ensemble.append(specificity)\n",
    "    precision_per_class_ensemble.append(precision)\n",
    "    f1score_per_class_ensemble.append(f1score)\n",
    "\n",
    "# Display the ensemble results in a DataFrame\n",
    "performance_df_ensemble = pd.DataFrame({\n",
    "    'Classes': class_names,\n",
    "    'Accuracy (%)': accuracy_per_class_ensemble,\n",
    "    'Sensitivity (%)': sensitivity_per_class_ensemble,\n",
    "    'Specificity (%)': specificity_per_class_ensemble,\n",
    "    'Precision (%)': precision_per_class_ensemble,\n",
    "    'F1 Score (%)': f1score_per_class_ensemble\n",
    "})\n",
    "\n",
    "# Add overall accuracy to match the table\n",
    "performance_df_ensemble['Overall Accuracy (%)'] = overall_accuracy_ensemble * 100\n",
    "\n",
    "print(performance_df_ensemble)\n",
    "\n",
    "# Plot ensemble confusion matrix\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(conf_matrix_ensemble, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title(f'Ensemble Confusion Matrix')\n",
    "plt.xlabel('Predicted Labels')\n",
    "plt.ylabel('True Labels')\n",
    "plt.show()\n",
    "\n",
    "# Plot accuracy and loss graphs for each model\n",
    "for name, history in histories.items():\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    \n",
    "    # Plot accuracy\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(np.array(history.history['accuracy']) * 100, 'o--', label='Train Accuracy')\n",
    "    plt.plot(np.array(history.history['val_accuracy']) * 100, 'o--', label='Validation Accuracy')\n",
    "    plt.title(f'{name} Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot loss\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'], 'o--', label='Train Loss')\n",
    "    plt.plot(history.history['val_loss'], 'o--', label='Validation Loss')\n",
    "    plt.title(f'{name} Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53970a9c-aa28-4e83-aef7-07cd3913896f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
